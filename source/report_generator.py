"""Report generator ‚Äî produces test-coverage documents from run data.

Takes structured run data (timing, requests, coverage results) stored
in the dashboard's data volume and generates formatted report files
with **identical** schema and format to the doc-sanitiser originals:

  - test-coverage.md
  - test-coverage-timing.json
  - test-coverage-requests-responses.md
  - test-coverage-requests-responses.json

Generated files are written to the run's ``reports/`` directory and
are browsable via the dashboard file browser UI.
"""

import json
import logging
from collections import OrderedDict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


# ===================================================================
# Coverage report rendering (test-coverage.md)
# ===================================================================

_STATUS_ICONS = {
    "passed": "‚úÖ",
    "failed": "‚ùå",
    "error": "üí•",
    "skipped": "‚è≠Ô∏è",
}

_TIER_LABELS = {
    "tests-unit": "Unit Tests",
    "tests-unit-with-llm": "Live LLM Tests",
    "tests-integration-with-llm": "Integration Tests (Docker + LLM)",
    "tests-integration": "Integration Tests",
    "tests-integration-full": "Full E2E Tests",
}

_TIER_ORDER = [
    "tests-unit",
    "tests-unit-with-llm",
    "tests-integration",
    "tests-integration-with-llm",
    "tests-integration-full",
]


def _format_duration(seconds: float) -> str:
    """Format a duration as a human-readable string."""
    if seconds < 0.001:
        return "<1ms"
    if seconds < 1.0:
        return f"{seconds * 1000:.0f}ms"
    if seconds < 60.0:
        return f"{seconds:.1f}s"
    minutes = int(seconds // 60)
    secs = seconds % 60
    return f"{minutes}m {secs:.1f}s"


def _get_tier(module_name: str) -> str:
    """Extract the test tier directory from a module name."""
    parts = module_name.rsplit(".", 1)
    return parts[0] if len(parts) == 2 else module_name


def _module_to_file_path(module_name: str) -> str:
    """Convert dotted module name to a relative file path."""
    parts = module_name.rsplit(".", 1)
    if len(parts) == 2:
        return f"{parts[0].replace('.', '/')}/{parts[1]}.py"
    return f"{module_name.replace('.', '/')}.py"


def _file_display_name(file_path: str) -> str:
    """Extract the filename from a file path for display."""
    return file_path.rsplit("/", 1)[-1] if "/" in file_path else file_path


def _render_coverage_markdown(coverage_data: Dict[str, Any]) -> str:
    """Render test-coverage.md from structured coverage data.

    The ``coverage_data`` dict must contain:
      - meta: {run_date, total, passed, failed, errors, skipped, elapsed}
      - files: [{module_name, file_path, classes: [{class_name, title,
                 description, order, tests: [{method_name, description,
                 status, detail, duration}]}]}]
      - file_order: [module_name, ...]
      - timeline_summary: (optional) time ledger data
    """
    meta = coverage_data.get("meta", {})
    files_list = coverage_data.get("files", [])
    file_order = coverage_data.get("file_order", [])
    timeline_summary = coverage_data.get("timeline_summary")

    # Build lookup by module_name
    files_by_module: Dict[str, Dict] = {}
    for f in files_list:
        files_by_module[f["module_name"]] = f

    # Sort modules
    sorted_modules = []
    for m in file_order:
        if m in files_by_module:
            sorted_modules.append(m)
    # Add any modules not in the explicit order
    for m in files_by_module:
        if m not in sorted_modules:
            sorted_modules.append(m)

    timestamp = meta.get("run_date", "")
    total = meta.get("total", 0)
    passed = meta.get("passed", 0)
    failed = meta.get("failed", 0)
    errors = meta.get("errors", 0)
    skipped = meta.get("skipped", 0)
    total_elapsed = meta.get("elapsed", 0.0)

    lines = []

    # Header
    lines.append("# Test Coverage Report ‚Äî doc-sanitiser")
    lines.append("")
    lines.append(
        "*Automatically generated by `python3 run_tests.py` "
        "‚Äî do not edit manually.*"
    )
    lines.append("")
    lines.append(f"**Run date**: {timestamp}  ")
    elapsed_str = _format_duration(total_elapsed) if total_elapsed > 0 else "N/A"
    lines.append(
        f"**Total**: {total} | "
        f"**Passed**: {passed} | "
        f"**Failed**: {failed} | "
        f"**Errors**: {errors} | "
        f"**Skipped**: {skipped} | "
        f"**Elapsed**: {elapsed_str}"
    )
    lines.append("")

    # Summary table
    lines.append("## Summary")
    lines.append("")
    lines.append(
        "| Test File | Tests | Passed | Failed | Errors | Skipped | Duration |"
    )
    lines.append(
        "|-----------|-------|--------|--------|--------|---------|----------|"
    )

    for module_name in sorted_modules:
        file_data = files_by_module[module_name]
        all_tests = [
            t for c in file_data.get("classes", []) for t in c.get("tests", [])
        ]
        f_total = len(all_tests)
        f_passed = sum(1 for t in all_tests if t.get("status") == "passed")
        f_failed = sum(1 for t in all_tests if t.get("status") == "failed")
        f_errors = sum(1 for t in all_tests if t.get("status") == "error")
        f_skipped = sum(1 for t in all_tests if t.get("status") == "skipped")
        f_duration = sum(t.get("duration", 0.0) for t in all_tests)
        display = _file_display_name(file_data.get("file_path", module_name))
        lines.append(
            f"| {display} | {f_total} | {f_passed} | "
            f"{f_failed} | {f_errors} | {f_skipped} | "
            f"{_format_duration(f_duration)} |"
        )

    lines.append("")

    # Detailed sections grouped by tier
    section_num = 0
    current_tier = None

    for module_name in sorted_modules:
        file_data = files_by_module[module_name]
        tier = _get_tier(module_name)

        # Tier header
        if tier != current_tier:
            current_tier = tier
            tier_label = _TIER_LABELS.get(tier, tier)
            tier_duration = sum(
                t.get("duration", 0.0)
                for mn in sorted_modules if _get_tier(mn) == tier
                for c in files_by_module[mn].get("classes", [])
                for t in c.get("tests", [])
            )
            lines.append("---")
            lines.append("")
            lines.append(
                f"## {tier_label} ({_format_duration(tier_duration)})"
            )
            lines.append("")

        section_num += 1
        display = _file_display_name(file_data.get("file_path", module_name))
        all_file_tests = [
            t for c in file_data.get("classes", []) for t in c.get("tests", [])
        ]
        file_total = len(all_file_tests)
        file_duration = sum(t.get("duration", 0.0) for t in all_file_tests)
        lines.append(
            f"### {section_num}. {display} "
            f"‚Äî {file_total} tests ({_format_duration(file_duration)})"
        )
        lines.append("")

        # Sort classes by order, then name
        sorted_classes = sorted(
            file_data.get("classes", []),
            key=lambda c: (c.get("order", 0), c.get("class_name", "")),
        )

        for class_data in sorted_classes:
            test_count = len(class_data.get("tests", []))
            subtitle = class_data.get("title", class_data.get("class_name", ""))
            description = class_data.get("description", "")
            if description:
                subtitle += f" ‚Äî {description}"
            lines.append(f"#### {subtitle} ({test_count} tests)")
            lines.append("")
            lines.append("| # | Test | Description | Status |")
            lines.append("|---|------|-------------|--------|")

            for i, test_data in enumerate(class_data.get("tests", []), 1):
                icon = _STATUS_ICONS.get(test_data.get("status", ""), "‚ùì")
                desc = test_data.get("description", "").replace("|", "\\|")
                name = test_data.get("method_name", "").replace("|", "\\|")
                lines.append(f"| {i} | {name} | {desc} | {icon} |")

                # Include failure/error details inline
                detail = test_data.get("detail")
                status = test_data.get("status", "")
                if detail and status in ("failed", "error"):
                    lines.append("")
                    lines.append(
                        f"<details><summary>{icon} "
                        f"{'Failure' if status == 'failed' else 'Error'}"
                        f" detail</summary>"
                    )
                    lines.append("")
                    lines.append("```")
                    lines.append(detail.rstrip())
                    lines.append("```")
                    lines.append("")
                    lines.append("</details>")
                    lines.append("")

            lines.append("")

    # Time Ledger
    if timeline_summary:
        lines.extend(_render_time_ledger(timeline_summary))

    return "\n".join(lines)


def _render_time_ledger(summary_data: Dict[str, Any]) -> List[str]:
    """Render the Time Ledger section from pre-computed summary data."""
    file_stats = summary_data.get("file_stats", [])
    total_elapsed = summary_data.get("total_elapsed", 0.0)
    total_overhead = summary_data.get("total_overhead", 0.0)

    if not file_stats or total_elapsed <= 0:
        return []

    lines = []
    lines.append("---")
    lines.append("")
    lines.append("## Time Ledger")
    lines.append("")
    lines.append(
        "*Full accounting of wall-clock time ‚Äî no gaps.  "
        "Every second between run-start and run-end is classified as "
        "test execution, class setUp/tearDown, or framework overhead.  "
        "Open `docs/test-coverage-timeline.html` for the interactive "
        "zoomable timeline.*"
    )
    lines.append("")

    lines.append(
        "| Category | setUp | Tests | tearDown | Total | % |"
    )
    lines.append(
        "|----------|-------|-------|----------|-------|---|"
    )

    grand_total_accounted = 0.0
    for fs in file_stats:
        su = fs.get("setup", 0.0)
        tt = fs.get("tests", 0.0)
        td = fs.get("teardown", 0.0)
        ftotal = su + tt + td
        grand_total_accounted += ftotal
        fk = fs.get("file", "")
        pct = (ftotal / total_elapsed * 100) if total_elapsed > 0 else 0
        lines.append(
            f"| üß™ {fk} "
            f"| {_format_duration(su)} "
            f"| {_format_duration(tt)} "
            f"| {_format_duration(td)} "
            f"| {_format_duration(ftotal)} "
            f"| {pct:.1f}% |"
        )

    grand_total_accounted += total_overhead
    if total_overhead > 0.001:
        pct = (total_overhead / total_elapsed * 100)
        lines.append(
            f"| ‚è≥ Framework overhead "
            f"| ‚Äî | ‚Äî | ‚Äî "
            f"| {_format_duration(total_overhead)} "
            f"| {pct:.1f}% |"
        )

    unaccounted = total_elapsed - grand_total_accounted
    if abs(unaccounted) > 0.01:
        pct = (unaccounted / total_elapsed * 100)
        lines.append(
            f"| ‚ùì Unaccounted "
            f"| ‚Äî | ‚Äî | ‚Äî "
            f"| {_format_duration(abs(unaccounted))} "
            f"| {pct:.1f}% |"
        )

    lines.append(
        f"| **TOTAL** "
        f"| | | "
        f"| **{_format_duration(total_elapsed)}** "
        f"| **100%** |"
    )
    lines.append("")

    return lines


# ===================================================================
# Request/Response report rendering
# ===================================================================

_MAX_PAYLOAD_CHARS = 2000
_MAX_LIST_ITEMS = 5
_MAX_STRING_LEN = 500


def _truncate_payload(obj: Any, max_chars: int = _MAX_PAYLOAD_CHARS) -> Any:
    """Truncate a JSON-serialisable payload for readable logging."""
    if obj is None:
        return None

    if isinstance(obj, str):
        if len(obj) > _MAX_STRING_LEN:
            return obj[:_MAX_STRING_LEN] + f"... ({len(obj)} chars total)"
        return obj

    if isinstance(obj, (int, float, bool)):
        return obj

    if isinstance(obj, list):
        if (
            len(obj) > 50
            and obj
            and isinstance(obj[0], (int, float))
        ):
            return f"[vector: {len(obj)} dims]"
        if len(obj) > _MAX_LIST_ITEMS:
            truncated = [_truncate_payload(item) for item in obj[:_MAX_LIST_ITEMS]]
            truncated.append(f"... ({len(obj)} items total)")
            return truncated
        return [_truncate_payload(item) for item in obj]

    if isinstance(obj, dict):
        result = {}
        for key, value in obj.items():
            if key == "embedding" and isinstance(value, list):
                result[key] = f"[vector: {len(value)} dims]"
            elif key == "data" and isinstance(value, list):
                result[key] = _truncate_payload(value)
            else:
                result[key] = _truncate_payload(value)
        return result

    return str(obj)


def _payload_was_truncated(raw: Any, truncated: Any) -> bool:
    """Check whether truncation changed the payload."""
    if raw is None and truncated is None:
        return False
    try:
        raw_json = json.dumps(raw, sort_keys=True, default=str)
        trunc_json = json.dumps(truncated, sort_keys=True, default=str)
        return raw_json != trunc_json
    except (TypeError, ValueError):
        return True


def _render_payload_block(
    lines: List[str],
    label: str,
    payload: Any,
    was_truncated: bool,
    full_path: Optional[str],
) -> None:
    """Render a single payload block (request or response) in markdown."""
    summary = f"{label} payload"
    if was_truncated and full_path:
        summary += f" ‚ö†Ô∏è truncated ‚Äî [full {label.lower()}]({full_path})"
    elif was_truncated:
        summary += " ‚ö†Ô∏è truncated"

    lines.append("<details>")
    lines.append(f"<summary>{summary}</summary>")
    lines.append("")
    lines.append("```json")
    try:
        lines.append(json.dumps(payload, indent=2, default=str))
    except (TypeError, ValueError):
        lines.append(str(payload))
    lines.append("```")
    lines.append("")
    lines.append("</details>")
    lines.append("")


def _render_requests_markdown(request_data: Dict[str, Any]) -> str:
    """Render test-coverage-requests-responses.md from structured data.

    The ``request_data`` dict must contain:
      - meta: {run_date, run_timestamp, total_requests, by_type, unique_tests}
      - entries: [{seq, timestamp, test_context, endpoint_type, url,
                   status_code, duration_ms, error, request_truncated,
                   response_truncated, thread_id, payloads, req_body, res_body}]
      - summary_by_test: [{test_context, total, llm, embedding, reranker, errors}]

    This is the **exact same schema** as test-coverage-requests-responses.json
    (schema_version 2). The markdown rendering is identical to the
    doc-sanitiser's ``RequestLogger._render_markdown()``.
    """
    meta = request_data.get("meta", {})
    entries = request_data.get("entries", [])
    summary_by_test = request_data.get("summary_by_test", [])

    run_date = meta.get("run_date", "")
    run_timestamp = meta.get("run_timestamp", "")
    total_requests = meta.get("total_requests", len(entries))
    by_type = meta.get("by_type", {})
    unique_tests = meta.get("unique_tests", len(summary_by_test))

    lines = []

    lines.append("# Request/Response Log ‚Äî doc-sanitiser")
    lines.append("")
    lines.append(
        "*Automatically generated during test runs "
        "‚Äî do not edit manually.*"
    )
    lines.append("")
    lines.append(f"**Run date**: {run_date}")
    lines.append(f"**Total requests**: {total_requests}")

    type_summary = ", ".join(
        f"{t}: {c}" for t, c in sorted(by_type.items())
    )
    lines.append(f"**By type**: {type_summary}")
    lines.append(f"**Unique tests**: {unique_tests}")

    # Payload folder link
    if entries:
        trunc_req = sum(
            1 for e in entries if e.get("request_truncated", False)
        )
        trunc_res = sum(
            1 for e in entries if e.get("response_truncated", False)
        )
        payloads_dir = meta.get("payloads_dir", f"request-payloads/{run_timestamp}/")
        lines.append(
            f"**Full payloads**: "
            f"[{payloads_dir}]"
            f"({payloads_dir}) "
            f"({total_requests} entries √ó 2 files"
            f"{f', {trunc_req} req + {trunc_res} res truncated in summary' if trunc_req or trunc_res else ''})"
        )
    lines.append("")

    # Summary table
    lines.append("## Summary by Test")
    lines.append("")
    lines.append("| # | Test | Requests | LLM | Embedding | Reranker | Errors |")
    lines.append("|---|------|----------|-----|-----------|----------|--------|")

    for i, test_stat in enumerate(summary_by_test, 1):
        ctx = test_stat.get("test_context", "")
        total = test_stat.get("total", 0)
        llm = test_stat.get("llm", 0)
        emb = test_stat.get("embedding", 0)
        rer = test_stat.get("reranker", 0)
        errs = test_stat.get("errors", 0)
        lines.append(
            f"| {i} | {ctx} | {total} | {llm} | {emb} | {rer} | {errs} |"
        )
    lines.append("")

    # Detailed entries
    lines.append("---")
    lines.append("")
    lines.append("## Detailed Request/Response Log")
    lines.append("")

    current_test = None
    for entry in entries:
        seq = entry.get("seq", 0)
        test_context = entry.get("test_context", "")
        endpoint_type = entry.get("endpoint_type", "")
        url = entry.get("url", "")
        status_code = entry.get("status_code", 0)
        duration_ms = entry.get("duration_ms", 0.0)
        error = entry.get("error")
        timestamp = entry.get("timestamp", "")
        req_body = entry.get("req_body")
        res_body = entry.get("res_body")
        request_truncated = entry.get("request_truncated", False)
        response_truncated = entry.get("response_truncated", False)
        payloads = entry.get("payloads", {})

        # Truncate for display
        truncated_req = _truncate_payload(req_body)
        truncated_res = _truncate_payload(res_body)

        # Recalculate truncation flags based on actual truncation
        req_was_truncated = _payload_was_truncated(req_body, truncated_req)
        res_was_truncated = _payload_was_truncated(res_body, truncated_res)

        # Group header when test changes
        if test_context != current_test:
            current_test = test_context
            lines.append(f"### {current_test}")
            lines.append("")

        status_icon = "‚úÖ" if status_code == 200 and not error else "‚ùå"
        lines.append(
            f"#### {status_icon} Request #{seq} ‚Äî "
            f"{endpoint_type} | {duration_ms}ms | "
            f"{timestamp}"
        )
        lines.append("")
        lines.append(f"**URL**: `{url}`  ")
        lines.append(f"**Status**: {status_code}  ")
        lines.append(f"**Duration**: {duration_ms}ms  ")

        if error:
            lines.append(f"**Error**: {error}  ")

        lines.append("")

        # Payload blocks
        req_path = payloads.get("req") if payloads else None
        res_path = payloads.get("res") if payloads else None

        _render_payload_block(
            lines, "Request", truncated_req, req_was_truncated, req_path,
        )
        _render_payload_block(
            lines, "Response", truncated_res, res_was_truncated, res_path,
        )

    return "\n".join(lines)


# ===================================================================
# Payload file writing
# ===================================================================

def _safe_filename(test_context: str) -> str:
    """Convert a test context to a safe filename component."""
    import re
    return re.sub(r"[^a-zA-Z0-9_.-]", "_", test_context)


def _write_payload_files(
    payloads_dir: Path,
    entries: List[Dict[str, Any]],
) -> Dict[int, Dict[str, str]]:
    """Write full payload JSON files for every entry.

    Returns:
        Dict mapping seq number ‚Üí {"req": relative_path, "res": relative_path}.
        Paths are relative to the reports/ directory.
    """
    payloads_dir.mkdir(parents=True, exist_ok=True)
    result: Dict[int, Dict[str, str]] = {}

    for entry in entries:
        seq = entry.get("seq", 0)
        endpoint_type = entry.get("endpoint_type", "unknown")
        test_context = entry.get("test_context", "unknown")
        safe_name = _safe_filename(test_context)
        prefix = f"{seq:04d}-{endpoint_type}-{safe_name}"

        paths: Dict[str, str] = {}

        # Write request file
        req_file = payloads_dir / f"{prefix}-req.json"
        req_body = entry.get("req_body")
        try:
            text = json.dumps(req_body, indent=2, ensure_ascii=False, default=str)
        except (TypeError, ValueError):
            text = str(req_body)
        req_file.write_text(text, encoding="utf-8")
        paths["req"] = f"request-payloads/{payloads_dir.name}/{req_file.name}"

        # Write response file
        res_file = payloads_dir / f"{prefix}-res.json"
        res_body = entry.get("res_body")
        try:
            text = json.dumps(res_body, indent=2, ensure_ascii=False, default=str)
        except (TypeError, ValueError):
            text = str(res_body)
        res_file.write_text(text, encoding="utf-8")
        paths["res"] = f"request-payloads/{payloads_dir.name}/{res_file.name}"

        result[seq] = paths

    return result


# ===================================================================
# Public API ‚Äî generate all 4 report files
# ===================================================================

def generate_reports(
    reports_dir: Path,
    *,
    coverage_data: Optional[Dict[str, Any]] = None,
    timing_data: Optional[Dict[str, Any]] = None,
    request_data: Optional[Dict[str, Any]] = None,
) -> Dict[str, str]:
    """Generate report files from structured data.

    All data blobs use the **exact same schema** as the doc-sanitiser
    originals ‚Äî schema_version 2 for timing and request JSON files.

    Args:
        reports_dir: Target directory for generated files.
        coverage_data: Structured test results for test-coverage.md.
        timing_data: Complete timing JSON (schema_version 2) for
            test-coverage-timing.json. Passed through as-is.
        request_data: Complete request/response JSON (schema_version 2)
            for test-coverage-requests-responses.json and .md.

    Returns:
        Dict of {filename: absolute_path} for all generated files.
    """
    reports_dir.mkdir(parents=True, exist_ok=True)
    generated: Dict[str, str] = {}

    # 1. test-coverage.md
    if coverage_data:
        md_path = reports_dir / "test-coverage.md"
        content = _render_coverage_markdown(coverage_data)
        md_path.write_text(content, encoding="utf-8")
        generated["test-coverage.md"] = str(md_path)
        logger.info("Generated %s", md_path)

    # 2. test-coverage-timing.json ‚Äî pass through as-is (identical schema)
    if timing_data:
        json_path = reports_dir / "test-coverage-timing.json"
        json_path.write_text(
            json.dumps(timing_data, indent=2, ensure_ascii=False),
            encoding="utf-8",
        )
        generated["test-coverage-timing.json"] = str(json_path)
        logger.info("Generated %s", json_path)

    # 3 & 4. request/response files
    if request_data:
        entries = request_data.get("entries", [])
        meta = request_data.get("meta", {})
        run_timestamp = meta.get("run_timestamp", "")

        # Write payload files
        if entries and run_timestamp:
            payloads_dir = reports_dir / "request-payloads" / run_timestamp
            payload_paths = _write_payload_files(payloads_dir, entries)

            # Update entries with payload paths
            for entry in entries:
                seq = entry.get("seq", 0)
                if seq in payload_paths:
                    entry["payloads"] = payload_paths[seq]

        # test-coverage-requests-responses.json ‚Äî pass through (identical schema)
        json_path = reports_dir / "test-coverage-requests-responses.json"
        json_path.write_text(
            json.dumps(request_data, indent=2, ensure_ascii=False, default=str),
            encoding="utf-8",
        )
        generated["test-coverage-requests-responses.json"] = str(json_path)
        logger.info("Generated %s", json_path)

        # test-coverage-requests-responses.md ‚Äî render from same data
        md_path = reports_dir / "test-coverage-requests-responses.md"
        content = _render_requests_markdown(request_data)
        md_path.write_text(content, encoding="utf-8")
        generated["test-coverage-requests-responses.md"] = str(md_path)
        logger.info("Generated %s", md_path)

    return generated
